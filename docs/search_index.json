[
["qualmethods.html", "Chapter 3 Qualitative Research Methods 3.1 Case Study 3.2 Narrative 3.3 Phenomenological 3.4 Ethnography 3.5 Grounded Theory", " Chapter 3 Qualitative Research Methods Qualitative Research Methods Field Guide 3.1 Case Study 3.2 Narrative 3.3 Phenomenological 3.4 Ethnography 3.5 Grounded Theory "],
["quantitative-methods.html", "Chapter 4 Quantitative Methods Causal Inference 4.1 Statistical Tests 4.2 Numerical Methods", " Chapter 4 Quantitative Methods Causal Inference These notes are based on Professor Masten’s online course on Causal Inference at the Social Science Research Institute at Duke. 4.0.1 Introduction Causal effect is often easy to detect with simple actions for which the effect immediately follows (e.g., you caused the alarm clock to stop ringing by pressing the snooze button) With multiple causes and delayed effects, causality is much harder to detect. Measurement: Unit of analysis: countries, city blocks, people, firms, etc. Outcome variable: the characteristic of the unit of analysis that we want to affect Policy/treatment variable: the characteristic that we use to change the outcome varialbe A lot of characteristics cannot readily be quantified, so we often use proxy variables. For example, GDP could be a proxy for economic development. Causality: how an intervention in the policy variable affects the outcome variable Data: The value of the policy variable has to vary in the dataset. Without this variation, you can’t analyze how changes in the policy variable might affect the outcome variable. Larger standard deviation = larger variation Correlation vs. Causation If the policy and outcome variables are correlated, this does not necessarily imply a casual relationship. Selection Problem: when units get to choose their policy variable, correlations between policy and outcome variables are unlikely to be causal. Example: Neighborhoods with a lot of trees tend to have less crime. If this were a casual relationship, then we could plant more trees in a neighborhood and expect crime to go down. However, this is unlikely. More likely, people who tend to commit less crimes chose to live in neighborhoods with tree-lined streets. Average Treatment Effect Causal effects vary among people, so there is a distribution of causal effects in the population. Theoretical ideal: you would know the unit level of causal effect for each person and thus make individualized treatment decisions. This is impossible in practice. You can’t know the effect of receiving and not receiving treatment for an individual. Unit-level causal effect: difference in outcome between treatment &amp; control, holding all other variables fixed Avg. treatment effect (ATE): avg. of all values for unit-level causal effects in a population Avg. outcome under the policy: avg. outcome when everyone is affected by the policy (i.e., receives treatment) Avg. outcome without the policy: avg. outcome when everyone is not affected by policy (i.e., does not receive treatment) ATE = Avg. outcome under policy - Avg. outcome w/o policy 4.0.2 Experiments Controlled Experiments Control group does not receive treatment Experimental group receives treatment All possible factors that could affect the outcome are identical for both groups, except for the treatment Difference in the outcome between the two groups is the treatment effect Typically used in hard sciences, but difficult to achieve in social sciences given the myriad of factors, many of which are difficult to measure and control Randomized Experiments Split units randomly into two large groups: treatment or control Right after randomization and before the experiment, both groups should be similar (i.e., avg. values of factors should be about the same), because the split was done randomly and the groups are very large Since the two groups are similar in all factors except treatment, changes in the average outcomes are due to treatment Complications: Noncompliance: Even when you randomly assign treatment, people in the treatment group may not all decide to take the treatment. Also, some people in the control group, who should not receive the treatment, might decide to get the treatment. Solution 1: Intent to Treat Analysis The intent to provide treatment is by design random regardless of treatment non-compliance. Thus, we can examine the causal effect of the option of providing treatment. Downside: cannot analyze causal effect of treatment itself For example, in the Oregon Health Experiment, while a lottery randomly selected people to receive free Medicaid, there was noncompliance in both the treatment/control groups. Original interpretation (effect of Medicaid on health outcomes) can be revised to effect of Medicaid lottery assignment on health outcomes. Solution 2: Instrumental Variables Advantage: We can analyze the causal effect of the treatment (not just the option of treatment) for a subset of the population. Downside: cannot analyze average treatment effect over the entire population Solution 3: Assume random compliance Assume people comply with their treatment assignment. Just drop the entries of the non-compliers. Advantage: We can analyze the causal effect of the treatment over the entire population. Downside: Decision to not comply is probably not random. We don’t observe the reasons for non-compliance. Solution 4: Bounds analysis Get lower/upper bounds of average treatment effects Survey nonresponse If nonresponse is not random, you cannot interpret the treatment effect as causal. Example: People in the treatment group with negative outcomes responded to surveys at higher rates than those with positive experiences. Data becomes biased toward negative outcomes for the treatment group. Sample Size: Even with a great research design, small sample size limits statistical inference. Control: You may not be able to control the assignment of treatment. Issues: Ethics: Random assignment of treatment may have difficult ethical considerations (e.g., withholding a potentially life-saving drug to a terminally ill patient assigned to a control group in a randomized trial). Extrapolation: It may be hard to extrapolate the results of a randomized experiment to another study if the treatment conditions and features are different. Natural Experiments Researchers not involved in the research design and data collection in natural experiments, unlike in randomized experiments. observational data used instead True Natural Experiments treatment was randomly assigned, just not by researcher As-If Natural Experiments treatment not actually randomly assigned, but the treatment/control groups appear randomized as though treatment assignment were random) treatment assignment not related to any variables that could affect outcome 4.0.3 Regression as Causality 4.0.4 Instrumental Variables 4.1 Statistical Tests Choosing a Statistical Test Hypothesis Testing Roadmap Chosing the Correct Statistical Test in SAS, Stata, SPSS, and R Uses &amp; Misuses of Statistics 1 group interval variables 1-sample t test for the mean chi-squared test for variance categorical variables z test for proportions (2 categories) chi-squared goodness-of-fit ordinal or interval one-sample median test 2 groups (independent groups) interval variables 2 independent sample t-test (equal variances) 2 independent sample t-test (unequal variances) F test for difference between 2 variances categorical variables z test for difference between 2 proportions chi-squared test for difference between 2 proportions Fisher’s exact test 2 groups (dependent or paired groups) paired t-test (interval variables) McNemar’s test (categorical variables) Wilcoxon signed ranks test (oridinal or interval variables) more than 2 groups (independent groups) one-way ANOVA (for interval variables) Kruskal Wallis (for ordinal or interval variables) chi-squared test (for categorical variables) more than 2 groups (dependent groups) one-way repeated measures ANOVA (for interval variables) repeated measures logistic regression (for categorical variables) Friedman test (for ordinal or interval) 4.1.1 1-sample t-test Assumptions: data is a simple random sample from population data follows normal distribution by Central Limit Theorm, with sample size \\(n&gt;=30\\), the sample mean is normally distributed regardless of the population distribution Two-tailed Hypothesis: \\[ H_0: \\mu = \\mu_0 \\] \\[ H_1: \\mu \\neq \\mu_0 \\] Test Statistic: \\[ T = \\frac{\\overline{X}-\\mu_0}{\\frac{S}{\\sqrt{n}}} \\sim t_{(n-1)} \\] \\(\\overline{X}\\) = sample mean \\(\\mu_0\\) = hypothesized population mean \\(S\\) = sample standard deviation \\(t_{(n-1)}\\) = \\(t\\) distribution with \\(n-1\\) degrees of freedom 4.1.2 chi-squared test for variance 4.1.3 z test for proportions Assumptions: sample proportion \\(p = \\frac{X}{n}\\) comes from random sample in population, where \\(X\\) is number of events of interest in sample size \\(n\\). \\(p\\) follows a binomial distribution, but we can assume normality when \\(X\\) and \\(n-X\\) are each at least 5 (old standards) or at least 15 (current standards) Two-tailed Hypothesis: \\[ H_0: \\pi = \\pi_0 \\] \\[ H_1: \\pi \\neq \\pi_0 \\] Test Statistic: \\[ z = \\frac{p-\\pi_0}{\\sqrt{\\frac{\\pi_0 (1-\\pi_0)}{n}}} \\sim \\mathcal{N}(0,1) \\] \\(\\pi_0\\) = hypothesized proportion \\(p\\) = sample proportion 4.1.4 t-test for 2 independent samples Assumptions: two independent samples are randomly selected from two populations with the same variance if you cannot use the assumption of same variance, use the Welch two-sample t-test test statistic is the same as below, but degrees of freedom are adjusted if populations are not normally distributed, the sample sizes \\(n_1\\) and \\(n_2\\) from the two populations needs to be at least 30 to ensure that the distribution of the sample means are normal by the Central Limit Theorem Two-tailed Hypothesis: \\[ H_0: \\mu_1 = \\mu_2 \\] \\[ H_1: \\mu_1 \\neq \\mu_2 \\] \\(\\mu_1\\) = population mean of 1st sample \\(\\mu_2\\) = population mean of 2nd sample Test Statistic: \\[ \\frac{ (\\overline{X}_1-\\overline{X}_2) - (\\mu_1 - \\mu_2) }{ \\sqrt{S_p^2 \\left( \\frac{1}{n_1} + \\frac{1}{n_2} \\right) } } \\sim t_{(n_1 + n_2 -2)} \\] \\[ S_p^2 = \\frac{(n_1-1)S_1^2 + (n_2-1)S_2^2}{(n_1-1)+(n_2-1)} \\] \\(S_p\\) = pooled variance \\(\\overline{X}_1\\) = mean of 1st sample \\(\\overline{X}_2\\) = mean of 2nd sample \\(S_1^2\\) = variance of 1st sample \\(S_2^2\\) = variance of 2nd sample More Info R Example includes examples under both assumptions of equal and unequal variances Andrew Heiss provides a brief tutorial with frequentist, simulation-based, and Bayesian approaches to comparing means between two groups. Also see Matti Vuorre’s tutorial for more details. 4.1.5 paired t-test Assumptions: More Info with R Example 4.1.6 chi-squared test for proportions The chi-squared test for 2 x 2 frequency tables is equivalent to the square of the z-test for two proportions. See this link for detailed explanation. 4.1.7 chi-squared test for independence Explain connection between chi-squared test for independence and log-linear models, which are Poisson models for categorical data. 4.1.8 ANOVA 4.2 Numerical Methods In AP Calculus, you mostly encountered problems that can be solved analytically. However, in research, many differential equation models do not have analytical forms and must be solved numerically. Matlab is often used in applied math, engineering, and physical sciences for such cases as well as other modeling applications. Octave is an open-source alternative to Matlab. While R not the first language that comes to mind for numerical methods, many numerical R packages have been developed as well as integration with Matlab, Octave, and Julia. Numerical Computing with Matlab This site has PDF versions of Cleve Moler’s textbook on numerical computing alongside a video series with lectures on differential equations and linear algebra by Prof. Gilbert Strang and computational video tutorials by Moler. Numerically Solving Differential Euqations with R 4.2.1 Root-Finding Algorithms Newton-Raphson Method Using R Bisection Method Using R Secant Method Using R 4.2.2 Numerical Solutions to Differential Equations Euler Method Using Matlab Runge-Kutta Methods "],
["resources-by-discipline.html", "Resources by Discipline Biology &amp; Biostatistics Economics &amp; Econometrics Psychology Public Health &amp; Epidemiology Social Sciences", " Resources by Discipline Biology &amp; Biostatistics Handbook of Biological Statistics An R Companion for the Handbook of Biological Statistics Economics &amp; Econometrics Introduction to Econometrics with R Principles of Econometrics with R Introduction to Data Science Using R for Introductory Econometrics Examples: Annotated Sample Econometrics Paper Microeconomic example of utility maximization constrained by budget lines Psychology Psychology Research Methods Public Health &amp; Epidemiology Examples: SIR Model Using R Social Sciences Social Science Methods Modules Applied Causal Analysis "]
]
